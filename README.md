# LLama2BlogGeneration
-Used this code to run llm model locally by downloadling (GGML)
-we can also use model directly from huggingface api
